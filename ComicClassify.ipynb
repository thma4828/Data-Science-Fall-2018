{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsmar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComicDataRaw = pd.read_csv(\"C:/Users/tsmar/dc-wikia-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComicDataRaw.fillna(value=0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComicData2 = ComicDataRaw.drop(labels=['urlslug', 'page_id', 'GSM', 'FIRST APPEARANCE', 'name'], axis=1) #drop unwanted cols\n",
    "len(ComicData2)\n",
    "#ComicData3 = ComicData2.fillna(0, axis=0) #drop rows with NaN values.\n",
    "ComicAlignment = ComicDataRaw.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6896"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ComicAlignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will be prediction the alignment of a superhero based on other data about them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6896"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComicData = ComicDataRaw.drop(labels=['ALIGN', 'urlslug', 'page_id', 'GSM', 'FIRST APPEARANCE', 'name'], axis=1)\n",
    "ComicData = ComicData.fillna(value=0, axis=0)\n",
    "\n",
    "len(ComicData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                    ID         EYE        HAIR                SEX  \\\n",
       "0     Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "1     Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "2     Secret Identity  Brown Eyes  Brown Hair    Male Characters   \n",
       "3     Public Identity  Brown Eyes  White Hair    Male Characters   \n",
       "4     Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "5     Public Identity   Blue Eyes  Black Hair  Female Characters   \n",
       "6     Public Identity   Blue Eyes  Blond Hair    Male Characters   \n",
       "7     Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "8     Public Identity   Blue Eyes  Blond Hair  Female Characters   \n",
       "9     Secret Identity   Blue Eyes  Blond Hair    Male Characters   \n",
       "10    Secret Identity   Blue Eyes  Blond Hair  Female Characters   \n",
       "11    Secret Identity   Blue Eyes  Blond Hair    Male Characters   \n",
       "12    Secret Identity   Blue Eyes    Red Hair  Female Characters   \n",
       "13    Public Identity   Blue Eyes  Brown Hair    Male Characters   \n",
       "14    Public Identity   Blue Eyes  Black Hair  Female Characters   \n",
       "15    Public Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "16    Secret Identity   Blue Eyes  Brown Hair    Male Characters   \n",
       "17    Secret Identity  Green Eyes  Black Hair    Male Characters   \n",
       "18    Public Identity  Brown Eyes           0    Male Characters   \n",
       "19    Public Identity  Green Eyes           0    Male Characters   \n",
       "20    Secret Identity  Green Eyes    Red Hair    Male Characters   \n",
       "21    Secret Identity   Blue Eyes  Blond Hair  Female Characters   \n",
       "22    Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "23    Public Identity  Green Eyes  Green Hair    Male Characters   \n",
       "24    Public Identity   Blue Eyes    Red Hair    Male Characters   \n",
       "25    Public Identity  Brown Eyes  Black Hair    Male Characters   \n",
       "26    Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "27    Public Identity   Blue Eyes    Red Hair    Male Characters   \n",
       "28    Public Identity  Green Eyes    Red Hair    Male Characters   \n",
       "29    Public Identity  Brown Eyes  Black Hair    Male Characters   \n",
       "...               ...         ...         ...                ...   \n",
       "6866  Secret Identity   Blue Eyes           0    Male Characters   \n",
       "6867                0           0           0    Male Characters   \n",
       "6868                0           0           0    Male Characters   \n",
       "6869                0           0  Black Hair    Male Characters   \n",
       "6870                0           0           0    Male Characters   \n",
       "6871  Secret Identity           0  Black Hair  Female Characters   \n",
       "6872                0           0           0    Male Characters   \n",
       "6873  Public Identity   Blue Eyes  Black Hair  Female Characters   \n",
       "6874                0           0           0    Male Characters   \n",
       "6875                0           0           0    Male Characters   \n",
       "6876  Secret Identity  Green Eyes    Red Hair    Male Characters   \n",
       "6877  Public Identity    Red Eyes           0    Male Characters   \n",
       "6878                0           0  Blond Hair  Female Characters   \n",
       "6879                0   Blue Eyes           0    Male Characters   \n",
       "6880  Public Identity           0  Black Hair    Male Characters   \n",
       "6881  Secret Identity  Green Eyes    Red Hair  Female Characters   \n",
       "6882  Public Identity  Brown Eyes  Brown Hair  Female Characters   \n",
       "6883  Secret Identity   Blue Eyes  Black Hair    Male Characters   \n",
       "6884  Secret Identity  Black Eyes  Black Hair    Male Characters   \n",
       "6885  Secret Identity  Green Eyes  Black Hair  Female Characters   \n",
       "6886                0           0           0    Male Characters   \n",
       "6887  Public Identity           0           0    Male Characters   \n",
       "6888  Public Identity           0           0    Male Characters   \n",
       "6889  Public Identity           0   Grey Hair    Male Characters   \n",
       "6890  Public Identity           0           0    Male Characters   \n",
       "6891  Public Identity           0           0  Female Characters   \n",
       "6892  Public Identity           0           0    Male Characters   \n",
       "6893  Public Identity           0           0    Male Characters   \n",
       "6894  Public Identity           0           0    Male Characters   \n",
       "6895  Public Identity   Blue Eyes  Blond Hair    Male Characters   \n",
       "\n",
       "                    ALIVE  APPEARANCES    YEAR  \n",
       "0       Living Characters       3093.0  1939.0  \n",
       "1       Living Characters       2496.0  1986.0  \n",
       "2       Living Characters       1565.0  1959.0  \n",
       "3       Living Characters       1316.0  1987.0  \n",
       "4       Living Characters       1237.0  1940.0  \n",
       "5       Living Characters       1231.0  1941.0  \n",
       "6       Living Characters       1121.0  1941.0  \n",
       "7       Living Characters       1095.0  1989.0  \n",
       "8       Living Characters       1075.0  1969.0  \n",
       "9       Living Characters       1028.0  1956.0  \n",
       "10      Living Characters       1028.0  1956.0  \n",
       "11    Deceased Characters        969.0  1940.0  \n",
       "12      Living Characters        951.0  1967.0  \n",
       "13      Living Characters        951.0  1940.0  \n",
       "14      Living Characters        934.0  1938.0  \n",
       "15      Living Characters        930.0  1943.0  \n",
       "16      Living Characters        803.0  1940.0  \n",
       "17      Living Characters        716.0  1994.0  \n",
       "18      Living Characters        706.0  1961.0  \n",
       "19      Living Characters        677.0  1986.0  \n",
       "20      Living Characters        654.0  1941.0  \n",
       "21      Living Characters        635.0  1976.0  \n",
       "22      Living Characters        605.0  1942.0  \n",
       "23      Living Characters        595.0  1965.0  \n",
       "24      Living Characters        593.0  1968.0  \n",
       "25      Living Characters        584.0  1980.0  \n",
       "26      Living Characters        560.0  1993.0  \n",
       "27    Deceased Characters        558.0  1960.0  \n",
       "28      Living Characters        557.0  1986.0  \n",
       "29      Living Characters        549.0  1971.0  \n",
       "...                   ...          ...     ...  \n",
       "6866    Living Characters          0.0  1967.0  \n",
       "6867    Living Characters          0.0  1967.0  \n",
       "6868    Living Characters          0.0  1967.0  \n",
       "6869    Living Characters          0.0  1967.0  \n",
       "6870    Living Characters          0.0  1967.0  \n",
       "6871    Living Characters          0.0  1966.0  \n",
       "6872    Living Characters          0.0  1966.0  \n",
       "6873    Living Characters          0.0  1965.0  \n",
       "6874    Living Characters          0.0  1963.0  \n",
       "6875    Living Characters          0.0  1962.0  \n",
       "6876    Living Characters          0.0  1960.0  \n",
       "6877    Living Characters          0.0  1955.0  \n",
       "6878    Living Characters          0.0  1948.0  \n",
       "6879    Living Characters          0.0  1946.0  \n",
       "6880    Living Characters          0.0  1946.0  \n",
       "6881    Living Characters          0.0  1944.0  \n",
       "6882  Deceased Characters          0.0  1941.0  \n",
       "6883    Living Characters          0.0  1941.0  \n",
       "6884    Living Characters          0.0  1940.0  \n",
       "6885    Living Characters          0.0  1940.0  \n",
       "6886    Living Characters          0.0  1936.0  \n",
       "6887    Living Characters          0.0     0.0  \n",
       "6888    Living Characters          0.0     0.0  \n",
       "6889    Living Characters          0.0     0.0  \n",
       "6890    Living Characters          0.0     0.0  \n",
       "6891    Living Characters          0.0     0.0  \n",
       "6892    Living Characters          0.0     0.0  \n",
       "6893    Living Characters          0.0     0.0  \n",
       "6894    Living Characters          0.0     0.0  \n",
       "6895    Living Characters          0.0     0.0  \n",
       "\n",
       "[6896 rows x 7 columns]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComicData.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, this dataframe needs to be converted into numerical data so that machine learning can be run on it. \n",
    "#lets build some dictionaries!!!!\n",
    "eye_map = {'Blue Eyes' : 1, 'Green Eyes' : 2, 'Brown Eyes' : 3, 'Black Eyes' : 4, 'Red Eyes' : 5, 'White Eyes' : 6,\n",
    "           'Hazel Eyes' : 7,  'Yellow Eyes' : 8, 'Purple Eyes' : 9, 'Orange Eyes' : 10, 'Pink Eyes' : 11, 'Silver Eyes' : 12,\n",
    "           'Gold Eyes' : 13, 'Grey Eyes' : 14, 'Photocellular Eyes' : 15, 'Amber Eyes' : 16, 'Violet Eyes':17, 'Auburn Hair':20, 0:0}\n",
    "\n",
    "hair_map = {'Blue Hair' : 1, 'Green Hair' : 2, 'Brown Hair' : 3, 'Black Hair' : 4, 'Red Hair' : 5, 'White Hair' : 6,\n",
    "           'Hazel Hair' : 7,  'Yellow Hair' : 8, 'Purple Hair' : 9, 'Orange Hair' : 10, 'Pink Hair' : 11, 'Silver Hair' : 12, \n",
    "            'Blond Hair' : 13, 'Strawberry Blond Hair' : 14, 'Gold Hair' : 15, 'Grey Hair' : 16, 'Reddish Brown Hair':17, 'Violet Hair':18,\n",
    "            'Platinum Blond Hair':19, 'Auburn Hair':20, 0:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = {'Secret Identity' : 0, 'Public Identity' : 1, 'Identity Unknown': 2, 0:0}\n",
    "gender_map = {'Male Characters' : 0, 'Female Characters' : 1, 'Genderless Characters': 2, 'Transgender Characters': 3, 0:0}\n",
    "alive_map = {'Living Characters' : 0, 'Deceased Characters' : 1, 0:0}\n",
    "align_map = {'Good Characters' : 0, 'Neutral Characters' : 1, 'Bad Characters' : 2, 'Reformed Criminals' : 3, 0:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will predict if a character is aligned to Good or Evil or Reformed based on these following data items:\n",
    "    #1. Gender,\n",
    "    #2. Eye Color\n",
    "    #3. is Alive\n",
    "    #4. Number of Appearences\n",
    "    #5. Year\n",
    "    #6. simple hash of their name.\n",
    "    #7. hair color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will turn list of alignments into list of numbers: \n",
    "import math\n",
    "num_align = [align_map[d] for d in ComicAlignment] #these are our labels. \n",
    "num_gender = [gender_map[g[3]] for g in ComicData.values]\n",
    "num_eye_color = [eye_map[c[1]] for c in ComicData.values]\n",
    "num_isAlive = [alive_map[a[4]] for a in ComicData.values]\n",
    "num_hair = [hair_map[h[2]] for h in ComicData.values]\n",
    "num_id = [id_map[p[0]] for p in ComicData.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Secret Identity', 'Blue Eyes', 'Black Hair', 'Male Characters',\n",
       "       'Living Characters', 3093.0, 1939.0], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComicData.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComicData['ID'] = num_id\n",
    "ComicData['EYE'] = num_eye_color\n",
    "ComicData['ALIVE'] = num_isAlive\n",
    "ComicData['HAIR'] = num_hair\n",
    "ComicData['SEX'] = num_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       ID  EYE  HAIR  SEX  ALIVE  APPEARANCES    YEAR\n",
       "0      0    1     4    0      0      0.77325  0.9695\n",
       "1      0    1     4    0      0      0.62400  0.9930\n",
       "2      0    3     3    0      0      0.39125  0.9795\n",
       "3      1    3     6    0      0      0.32900  0.9935\n",
       "4      0    1     4    0      0      0.30925  0.9700\n",
       "5      1    1     4    1      0      0.30775  0.9705\n",
       "6      1    1    13    0      0      0.28025  0.9705\n",
       "7      0    1     4    0      0      0.27375  0.9945\n",
       "8      1    1    13    1      0      0.26875  0.9845\n",
       "9      0    1    13    0      0      0.25700  0.9780\n",
       "10     0    1    13    1      0      0.25700  0.9780\n",
       "11     0    1    13    0      1      0.24225  0.9700\n",
       "12     0    1     5    1      0      0.23775  0.9835\n",
       "13     1    1     3    0      0      0.23775  0.9700\n",
       "14     1    1     4    1      0      0.23350  0.9690\n",
       "15     1    1     4    0      0      0.23250  0.9715\n",
       "16     0    1     3    0      0      0.20075  0.9700\n",
       "17     0    2     4    0      0      0.17900  0.9970\n",
       "18     1    3     0    0      0      0.17650  0.9805\n",
       "19     1    2     0    0      0      0.16925  0.9930\n",
       "20     0    2     5    0      0      0.16350  0.9705\n",
       "21     0    1    13    1      0      0.15875  0.9880\n",
       "22     0    1     4    0      0      0.15125  0.9710\n",
       "23     1    2     2    0      0      0.14875  0.9825\n",
       "24     1    1     5    0      0      0.14825  0.9840\n",
       "25     1    3     4    0      0      0.14600  0.9900\n",
       "26     0    1     4    0      0      0.14000  0.9965\n",
       "27     1    1     5    0      1      0.13950  0.9800\n",
       "28     1    2     5    0      0      0.13925  0.9930\n",
       "29     1    3     4    0      0      0.13725  0.9855\n",
       "...   ..  ...   ...  ...    ...          ...     ...\n",
       "6866   0    1     0    0      0      0.00000  0.9835\n",
       "6867   0    0     0    0      0      0.00000  0.9835\n",
       "6868   0    0     0    0      0      0.00000  0.9835\n",
       "6869   0    0     4    0      0      0.00000  0.9835\n",
       "6870   0    0     0    0      0      0.00000  0.9835\n",
       "6871   0    0     4    1      0      0.00000  0.9830\n",
       "6872   0    0     0    0      0      0.00000  0.9830\n",
       "6873   1    1     4    1      0      0.00000  0.9825\n",
       "6874   0    0     0    0      0      0.00000  0.9815\n",
       "6875   0    0     0    0      0      0.00000  0.9810\n",
       "6876   0    2     5    0      0      0.00000  0.9800\n",
       "6877   1    5     0    0      0      0.00000  0.9775\n",
       "6878   0    0    13    1      0      0.00000  0.9740\n",
       "6879   0    1     0    0      0      0.00000  0.9730\n",
       "6880   1    0     4    0      0      0.00000  0.9730\n",
       "6881   0    2     5    1      0      0.00000  0.9720\n",
       "6882   1    3     3    1      1      0.00000  0.9705\n",
       "6883   0    1     4    0      0      0.00000  0.9705\n",
       "6884   0    4     4    0      0      0.00000  0.9700\n",
       "6885   0    2     4    1      0      0.00000  0.9700\n",
       "6886   0    0     0    0      0      0.00000  0.9680\n",
       "6887   1    0     0    0      0      0.00000  0.0000\n",
       "6888   1    0     0    0      0      0.00000  0.0000\n",
       "6889   1    0    16    0      0      0.00000  0.0000\n",
       "6890   1    0     0    0      0      0.00000  0.0000\n",
       "6891   1    0     0    1      0      0.00000  0.0000\n",
       "6892   1    0     0    0      0      0.00000  0.0000\n",
       "6893   1    0     0    0      0      0.00000  0.0000\n",
       "6894   1    0     0    0      0      0.00000  0.0000\n",
       "6895   1    1    13    0      0      0.00000  0.0000\n",
       "\n",
       "[6896 rows x 7 columns]>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComicData['APPEARANCES'] = ComicData['APPEARANCES'] / 4\n",
    "ComicData['YEAR'] = ComicData['YEAR'] / 2\n",
    "ComicData.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6896"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we have our labels: \n",
    "len(num_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the data is ready! we can go to work!\n",
    "#lets split up the data into training, validation, testing\n",
    "TrainSplit = 0.50\n",
    "ValidSplit = 0.25\n",
    "TestSplit = 0.25\n",
    "\n",
    "data_size = 6896\n",
    "train_len = int(data_size * TrainSplit)\n",
    "valid_len = int(data_size * ValidSplit)\n",
    "test_len = int(data_size * TestSplit)\n",
    "\n",
    "TrainSet = ComicData.values[:train_len]\n",
    "TrainLabels = num_align[:train_len]\n",
    "\n",
    "ValidationSet = ComicData.values[train_len+1:train_len+valid_len+1]\n",
    "ValidationLabels = num_align[train_len+1:train_len+valid_len+1]\n",
    "\n",
    "TestSet = ComicData.values[train_len + valid_len:]\n",
    "TestLabels = num_align[train_len + valid_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsmar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, input_dim=7, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\tsmar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\tsmar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\tsmar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=7, activation='relu', init='uniform'))\n",
    "model.add(Dense(16, activation='relu', init='uniform'))\n",
    "model.add(Dense(8, activation='relu', init='uniform'))\n",
    "model.add(Dense(5, activation='softmax', init='uniform'))\n",
    "model.compile(optimizer=Adam(lr=0.02),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3448"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet = np.reshape(TrainSet, (train_len, 7))\n",
    "TrainLabelSet = []\n",
    "for t in TrainLabels:\n",
    "    if t == 0:\n",
    "        TrainLabelSet.append([1, 0, 0, 0, 0])\n",
    "    elif t == 1:\n",
    "        TrainLabelSet.append([0, 1, 0, 0, 0])\n",
    "    elif t == 2:\n",
    "        TrainLabelSet.append([0, 0, 1, 0, 0])\n",
    "    elif t == 3:\n",
    "        TrainLabelSet.append([0, 0, 0, 1, 0])\n",
    "    elif t == 4:\n",
    "        TrainLabelSet.append([0, 0, 0, 0, 1])\n",
    "ValidationSet = np.reshape(ValidationSet, (valid_len, 7))\n",
    "ValidLabelSet = []\n",
    "for t in ValidationLabels:\n",
    "    if t == 0:\n",
    "        ValidLabelSet.append([1, 0, 0, 0, 0])\n",
    "    elif t == 1:\n",
    "        ValidLabelSet.append([0, 1, 0, 0, 0])\n",
    "    elif t == 2:\n",
    "        ValidLabelSet.append([0, 0, 1, 0, 0])\n",
    "    elif t == 3:\n",
    "        ValidLabelSet.append([0, 0, 0, 1, 0])\n",
    "    elif t == 4:\n",
    "        ValidLabelSet.append([0, 0, 0, 0, 1])\n",
    "        \n",
    "TestSet = np.reshape(TestSet, (test_len, 7))\n",
    "TestLabelSet = []\n",
    "for t in TestLabels:\n",
    "    if t == 0:\n",
    "        TestLabelSet.append([1, 0, 0, 0, 0])\n",
    "    elif t == 1:\n",
    "        TestLabelSet.append([0, 1, 0, 0, 0])\n",
    "    elif t == 2:\n",
    "        TestLabelSet.append([0, 0, 1, 0, 0])\n",
    "    elif t == 3:\n",
    "        TestLabelSet.append([0, 0, 0, 1, 0])\n",
    "    elif t == 4:\n",
    "        TestLabelSet.append([0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3448/3448 [==============================] - 1s 331us/step - loss: 1.1889 - acc: 0.4927\n",
      "Epoch 2/3\n",
      "3448/3448 [==============================] - 0s 45us/step - loss: 1.1523 - acc: 0.4983\n",
      "Epoch 3/3\n",
      "3448/3448 [==============================] - 0s 46us/step - loss: 1.1484 - acc: 0.4983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x205e82a3da0>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(TrainSet, np.array(TrainLabelSet), epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1724/1724 [==============================] - 0s 55us/step - loss: 1.1175 - acc: 0.5023\n",
      "Epoch 2/3\n",
      "1724/1724 [==============================] - 0s 48us/step - loss: 1.1088 - acc: 0.5151\n",
      "Epoch 3/3\n",
      "1724/1724 [==============================] - 0s 47us/step - loss: 1.1155 - acc: 0.5174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x205e7fa0e80>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ValidationSet, np.array(ValidLabelSet), epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724/1724 [==============================] - 0s 196us/step\n",
      "\n",
      "acc: 52.09%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(TestSet, np.array(TestLabelSet))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
